{
 "metadata": {
  "name": "",
  "signature": "sha256:0c81c8fbab0ba9d31230db8a41c93653442ea27fc511af6618922659dee02697"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import tweepy\n",
      "import time\n",
      "import pandas as pd\n",
      "import re\n",
      "import collections\n",
      "import json\n",
      "from datetime import datetime\n",
      "import pickle\n",
      "\n",
      "consumer_key ='pX1VF2Mp5FicThnpyWmP7GyH3'\n",
      "consumer_secret = 'zuesUN6OPburvzMssJivbGNwgjfSj3vNCaJ4hbH9WrZlbwhweM'\n",
      "access_token = '440434796-7YLC6Tnpv8beLCjVhHXLxa9XLxC1aoYI4iP2XrNy'\n",
      "access_token_secret = '0VzybqOTxPoUQLeuAdmsdAmOtCCyDdPb8wIht12Vg2ukP'\n",
      "\n",
      "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
      "auth.set_access_token(access_token, access_token_secret)\n",
      "\n",
      "api = tweepy.API(auth)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_entry(entry):\n",
      "\t#row = pd.DataFrame(columns= [\"created_at\", \"user\", \"favs\", \"rt\", \"lang\", \"text\", \"user_pic\"])\n",
      "\trow = pd.Series()\n",
      "\trow[\"created_at\"] = str(entry.created_at)\n",
      "\trow[\"user\"] = entry.user.screen_name.encode(\"utf-8\")\n",
      "\trow[\"favs\"] = entry.favorite_count\n",
      "\trow[\"rt\"] = entry.retweet_count\n",
      "\trow[\"lang\"] = entry.lang.encode(\"utf-8\")\n",
      "\trow[\"time_zone\"] = get_time_zone(entry)\n",
      "\trow[\"text\"] = entry.text.encode(\"utf-8\")\n",
      "\trow[\"user_pic\"] = entry.user.profile_image_url.encode(\"utf-8\")\n",
      "\t\n",
      "\treturn row\n",
      "\n",
      "def get_time_zone(entry):\n",
      "\tif entry._json[\"user\"][\"time_zone\"] == None:\n",
      "\t\treturn \"N/A\"\n",
      "\telse:\n",
      "\t\treturn entry._json[\"user\"][\"time_zone\"].encode(\"utf-8\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"/home/honu/projects/tweetpeek/db/raw_data/\" + \"2015-06-17_\" + \"#3PalabrasAntesDelSexo.txt\", 'rb') as f:\n",
      "    data = pickle.load(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "2700"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "today = str(datetime.today())[:10]\n",
      "data_text = \"\"\n",
      "\n",
      "for i in data:\n",
      "    data_text = ' '.join([data[i].text.lower() for i in xrange(len(data))]).encode('utf-8')\n",
      "\n",
      "hashtags = []\n",
      "mentions = []\n",
      "\n",
      "for i in data:\n",
      "    for j in i._json[\"entities\"][\"hashtags\"]:\n",
      "        hashtags.append(j[\"text\"].encode('utf-8'))\n",
      "    for j in i._json[\"entities\"][\"user_mentions\"]:\n",
      "        mentions.append(j[\"screen_name\"].encode('utf-8'))\n",
      "\n",
      "hashtags_frequency = collections.Counter(hashtags)\n",
      "mentions_frequency = collections.Counter(mentions)\n",
      "\n",
      "df = pd.DataFrame(columns= [\"created_at\", \"user\", \"favs\", \"rt\", \"lang\", \"time_zone\", \"text\", \"user_pic\"])\n",
      "for entry in data:\n",
      "    df = df.append(load_entry(entry), ignore_index = True)\n",
      "\n",
      "output = {}\n",
      "top_hashtags = hashtags_frequency.most_common(10)\n",
      "top_users = mentions_frequency.most_common(10)\n",
      "most_fav = df[df[\"favs\"] == df[\"favs\"].max()].head(1)\n",
      "most_rt = data[df[df[\"rt\"] == df[\"rt\"].max()].head(1).index[0]].retweeted_status\n",
      "time_zones = collections.Counter(df[\"time_zone\"]).most_common(25)\n",
      "output[\"len\"] = str(len(df))\n",
      "output[\"lang\"] = [[df[\"lang\"].value_counts().head().index[i], str(df[\"lang\"].value_counts().head().values[i])] for i in xrange(5)]\n",
      "output[\"time_zones\"] = [[entry[0], str(entry[1])] for entry in time_zones]\n",
      "output[\"hashtags\"] = [[top_hashtags[i][0], str(top_hashtags[i][1])] for i in xrange(10)]\n",
      "output[\"users\"] = [[top_users[i][0], str(top_users[i][1])] for i in xrange(10)]\n",
      "output[\"most_fav\"] = {\"user\": str(most_fav[\"user\"][most_fav.index[0]]), \"user_pic\": str(most_fav[\"user_pic\"][most_fav.index[0]]), \"text\": str(most_fav[\"text\"][most_fav.index[0]]), \"favs\": str(most_fav[\"favs\"][most_fav.index[0]]), \"rt\": str(most_fav[\"rt\"][most_fav.index[0]]), \"created_at\": str(most_fav[\"created_at\"][most_fav.index[0]])}\n",
      "output[\"most_rt\"] = {\"user\": str(most_rt.user.screen_name.encode(\"utf-8\")), \"user_id\": str(most_rt.user.id),\"user_pic\": str(most_rt.user.profile_image_url.encode(\"utf-8\")), \"text\": most_rt.text.encode(\"utf-8\"), \"tweet_id\": str(most_rt.id), \"favs\": str(most_rt.favorite_count), \"rt\": str(most_rt.retweet_count), \"created_at\": str(most_rt.created_at)}\n",
      "output[\"text\"] = data_text\n",
      "json_output = json.dumps(output)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data[df[df[\"favs\"] == df[\"favs\"].max()].head(1).index[0]].text\n",
      "#for i in xrange(200):\n",
      "#    print data[i].text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "u'Computa encuesta Durex #3PalabrasAntesDelSexo'"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"/home/honu/projects/tweetpeek/db/trends/2015-06-19_trends.txt\", 'rb') as f:\n",
      "    trends = pickle.load(f)\n",
      "print trends"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['M\\xe3\\x82\\xb9\\xe3\\x83\\x86', '#nationalkissingday', '#LoveMeRight7thWin', '#FueraFelipeVI', '#\\xd8\\xb4\\xd9\\x8a_\\xd8\\xaa\\xd8\\xb9\\xd8\\xb1\\xd9\\x81\\xd9\\x87_\\xd8\\xb9\\xd9\\x86_\\xd8\\xa7\\xd9\\x84\\xd8\\xa7\\xd8\\xb1\\xd8\\xaf\\xd9\\x86\\xd9\\x8a\\xd9\\x8a\\xd9\\x86', '#HepimizPYDliyiz', '\\xe3\\x81\\xa7\\xe3\\x82\\x93\\xe3\\x81\\xb1\\xe7\\xb5\\x84', 'Alexandros', '\\xe3\\x83\\x89\\xe3\\x83\\xad\\xe3\\x82\\xb9', 'Jon Stewart']\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in trends:\n",
      "    print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "#CharlestonShooting\n",
        "#NoTeEnvioUnWhatsAppPorque\n",
        "#\u062e\u0648\u0627\u0637\u063111\n",
        "#MTVBattleFifthHarmony\n",
        "#AskAmell\n",
        "Confederate\n",
        "Paul McCartney\n",
        "F\u00e1bio Martins\n",
        "Sel\u00e7uk \u015eahin\n",
        "Nikki Haley\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[\"lang\"].value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "es     2271\n",
        "pt      140\n",
        "en      118\n",
        "it       39\n",
        "und      38\n",
        "in       31\n",
        "fr       14\n",
        "ht        9\n",
        "tl        9\n",
        "sk        8\n",
        "sv        4\n",
        "sl        3\n",
        "no        3\n",
        "tr        3\n",
        "lt        2\n",
        "hu        2\n",
        "et        2\n",
        "ja        1\n",
        "is        1\n",
        "nl        1\n",
        "de        1\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 25
    }
   ],
   "metadata": {}
  }
 ]
}